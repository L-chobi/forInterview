## 대용량 트래픽 처리의 필요성
- 여러 회사의 우대 사항이나 필수 조건을 보면 "대용량 트래픽 처리에 대한 경험이나 지식" 이란 항목이 있는 것을 어렵지 않게 찾을 수 있다. 
- 트래픽이란 구글 사전의 의미로는 통신망을 통과하는 정보의 흐름으로, 통신장치나 시스템에 걸리는 부하를 의미한다. 그냥 쉽게 말해서 우리가 어떤 웹 서비스를 이용할 때 그로 인해 발생하는 요청이나 응답 등을 다 합친 것이라고 표현할 수 있을 것 같다. 더 쉽게는 그냥 일정 시간 내에 이동하는 데이터의 전송량을 뜻한다.
- 파일을 다운받거나 업로드하는 것도 트래픽이 발생하는 요소다. 예를 들어 어떤 사진 파일 하나가 3mb라고 가정하자. 그 사진 파일이 엄청 인기가 있어서 한 만명 정도가 그 파일을 동시에 다운받았다고 가정하자. 이럴 경우 발생한 트래픽은 3*10000mb로, 무려 30gb가 된다.
- 물론 한 파일을 동시에 만명이 다운받는 경우는 드물겠지만 3mb 보다 큰 여러 파일들을 많은 유저가 동시에 다운받거나 업로드 하는 경우는 충분히 있을 법한 일이고, 30gb는 애교로 보일 정도로 더 많은 트래픽이 발생하는 서비스도 존재할 수 있을 것이다(네이버, 카카오라던가). 
- 아무튼 동시 접속자가 많아져 서버 내의 리소스가 부족하게 되거나 이런 저런 이유로 트래픽을 감당하지 못하게되면 서버 등에 장애가 발생하고, 이런 장애의 발생은 결국 시스템 장애나 최악의 경우 시스템 다운으로 이어질 것이다. 
- 즉, 대용량 트래픽이란 개발자에게 있어서 결국 마주치게 되고, 해결해야할 문제라 할 수 있을 것이다.
- 그렇다면 어떻게 이 문제에 대응할 수 있을까? 쉽게 말하면 그런 트래픽을 감당할만한 리소스를 확보할 수 있는 구조를 설계하면 된다. 그리고 이 방식엔 스케일 아웃, 스케일 업 방식이 존재한다.

## 스케일 업, 스케일 아웃
### 스케일 업?
- 스케일 업이란 수직적 확장이라 불리며 서버 한 대의 하드웨어 성능을 높여 서버의 성능을 높이는 전략이다. 컴퓨터의 그래픽 카드를 더 좋은 그래픽 카드로 바꾸는 것과 비슷하다고 보면 된다.

### 스케일 업의 장점
- 스케일 업 방식은 서버 하나의 성능을 높이는 것이기에 자원의 변경에 따른 어플리케이션의 영향이 적다. 
- 또한 모든 데이터 처리가 단일 서버에서 이루어져 데이터의 일관성이나 정합성이 지켜진다.

### 스케일 업의 단점
- 그러나 그래픽 카드도 좋은 것일수록 가격이 매우 높아지듯이, 스케일 업 방식도 스케일 아웃에 비해 비용이 많이 든다. 
- 또한 결국 서버 하나를 이용하는 것이기에 이런저런 이유로 그 서버에 문제가 생길 경우 시스템 전체에 영향을 끼치게 된다(SPOF).

### SPOF란?
- 단일 장애점이라는 이름으로, 시스템 구성요소 중 어느 하나에 문제가 발생하면 전체 시스템이 중단되는 것을 말한다.

### 스케일 아웃?
- 스케일 아웃은 수평적 확장이라 불리며 서버 하나가 아닌 그와 비슷한 수준이나 낮은 사양의 서버 여러 대를 사용하는 방식이다.

### 스케일 아웃의 장점
- 스케일 업에 비해 비용이 저렴하다. 
- 또한 필요에 따라 서버를 증설하고 제거하는 것이 용이하기 때문에 좀 더 유연한 확장이 가능하다.
- 서버 하나에 장애가 생기더라도 나머지 서버들이 감당하면 되므로 좀 더 안정적이다(SPOF 해결 가능).

### 스케일 아웃의 단점
- 그러나 기본적으로 여러 대의 서버를 사용하는 것이기에 이를 구축, 유지, 관리하기 위한 지식과 경험이 필수적이다.
- 또한 이런 분산 서버 환경을 위한 로드 밸런싱, 로드 밸런싱과 데이터, 서비스를 위한 이중화 등 다양한 지식이 필요하다.
- 데이터 불일치가 발생할 수 있다(은행 등 정확한 데이터가 필요한 서비스에는 좋지 않음).

## 로드 밸런서(LB, Load Balancer)
- 로드 밸런싱이란 번역하면 부하 분산으로, 하나의 서버 등에 몰리는 요청 등의 부하를 여러 서버에 분산시키는 것을 말한다. 로드 밸런서는 이런 로드 밸런싱 기능을 수행하는 장치를 말한다.
- 스케일 아웃 방식을 사용하게 되면 클라이언트의 요청을 여러 서버에게 나눠줘야 하는데, 이 역할을 로드 밸런서가 수행한다.
- 서버의 앞단에 위치하여 정해진 알고리즘(라운드 로빈, 가중 라운드 로빈, 최소 연결 방식 등)에 따라 요청을 서버들에게 분산시켜 시스템을 안정화한다.

### 로드 밸런싱 알고리즘
1. 라운드 로빈
- 서버에 들어온 요청을 순서대로 돌아가며 배정
- 각 서버의 스펙과 성능이 비슷하고, 세션이 오래 지속되지않는 경우에 적합

2. 가중 라운드 로빈
- 각각의 서버에 가중치를 매기고 가중치가 높은 서버에 우선적으로 배정
- 각 서버의 트래픽 처리 속도가 다를 경우에 적합

3. IP 해시 방식
- 클라이언트의 IP주소를 해시 함수를 통해 특정 서버에 매핑
- 사용자가 항상 동일한 서버로 연결되는 것을 보장

4. 최초 연결 방식
- 요청이 들어온 시점에 가장 적은 연결 상태를 보이는 서버에 우선적으로 배정
- 서버에 분배된 트래픽이 일정하지 않은 경우 적합

5. 최소 응답시간 방식
- 서버의 현재 연결 상태와 응답시간을 모두 고려해 트래픽을 배분

### 로드 밸런싱 종류
1. L4 로드 밸런싱
- 전송 계층(4계층)에서 로드를 분산
- IP 주소나 포트번호, MAC 주소 등에 따라 트래픽을 나누고 분산처리가 가능
- CLB(Connecton Load Balancer) 혹은 SLB(Session Load Balancer)라고 부르기도 함

2. L7 로드 밸런싱
- 애플리케이션 계층(7계층)에서 로드를 분산
- OSI 7계층의 프로토콜을 바탕으로도 분산 처리가 가능(URL, HTTP 헤더의 쿠키 값 등)

## 로드 밸런서 이중화
- 

## 스케일 아웃에서 발생하는 데이터 불일치
- 대부분의 웹 서비스는 상태정보를 저장해야 한다(stateful 하다). 
- 로그인 여부나 기타 정보 등으로 서비스를 제공하기 때문인데, 스케일 아웃처럼 서버를 분산시켰을 경우 세션 정보 또한 분산되기 때문에 이 문제를 해결할 수 있어야 한다.

### Sticky session 방법
- sticky session 방법은 사용자를 해당 사용자의 세션을 생성한 서버에 바인딩하여 이후 동일한 사용자로부터 들어오는 모든 요청을 동일한 서버로 보내는 것을 말한다. 이름 그대로 딱 붙어있는 방법이다. 
- 그러나 이런 방법은 하나의 서버에 트래픽이 몰릴 수 있고, 그 서버가 다운되면 세션 정보가 사라질 수 있기 때문에 좋은 방법은 아니다.

### Session clustering(세션 클러스터링)
- 여러 서버에 흩어진 세션들을 하나의 그룹으로 묶어 동일한 세션으로 관리하는 것을 말한다. A 서버에 세션 정보가 수정되거나 생성되면 해당 정보를 B나 C 서버에도 복제하게 된다.
- 이 방법을 사용할 경우 사용자의 요청이 다른 서버로 흘러가도 그 서버에도 해당 사용자의 세션 정보가 존재하기에 문제가 일어나지 않는다.
- 그러나 세션을 다른 서버에 복제하는 등의 세션 관리 자체가 메모리를 사용하고 네트워크 트래픽도 증가하기에 서비스 이용자가 증가할수록 이를 위한 부하 또한 증가한다.

### Session storage(세션 스토리지) 분리
- 위의 두 방법과는 다르게 세션만을 저장하는 저장소를 별개로 두어 이 저장소에 세션 정보를 공유하는 방법이다.
- 이 방법을 적용하면 서버들은 해당 저장소의 정보만 알고 있으면 되기 때문에 서버는 더이상 사용자의 세션을 담당하지 않아도 되고, 세션 복제로 인한 비용도 발생하지 않는다.
- 하나의 저장소에서 세션을 관리하기 때문에 정합성 이슈 또한 해결된다.
- 다만 하나의 저장소를 사용하기에 해당 저장소가 다운되면 모든 서버가 세션 정보를 이용할 수 없다. 그러니 해당 저장소를 복제하여 장애에 대비해야 한다.


